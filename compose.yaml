# ===========================================================================
# Qwen3-TTS â€” Text-to-Speech GPU service
#
# Joins freepbx-net so voice-platform can reach it as "qwen3-tts"
#
# Usage:
#   docker compose up -d
# ===========================================================================

networks:
  freepbx-net:
    external: true

services:
  qwen3-tts:
    container_name: qwen3-tts
    build:
      context: .
    image: qwen3-tts-local:cuda124
    restart: unless-stopped
    environment:
      MODEL_ID: "Qwen/Qwen3-TTS-12Hz-0.6B-Base"
      PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
      REQUEST_TIMEOUT: "300"
      IDLE_TIMEOUT: "0"
      AUDIO_CACHE_MAX: "256"
      TORCH_COMPILE: "true"
      TORCH_COMPILE_MODE: "max-autotune"
      CUDA_GRAPHS: "true"
      VAD_TRIM: "true"
      TEXT_NORMALIZE: "true"
      VOICE_CACHE_MAX: "32"
      PRELOAD_MODEL: "true"
      LD_PRELOAD: "/usr/lib/x86_64-linux-gnu/libjemalloc.so.2"
      MALLOC_CONF: "background_thread:true,dirty_decay_ms:1000,muzzy_decay_ms:0"
      INFERENCE_CPU_CORES: ""
      MAX_QUEUE_DEPTH: "5"
      UNIX_SOCKET_PATH: ""
      SSL_KEYFILE: ""
      SSL_CERTFILE: ""
      QUANTIZE: ""
      GATEWAY_MODE: "false"
    ports:
      - "8101:8000"
    volumes:
      - ./models:/root/.cache/huggingface
    networks:
      - freepbx-net
    ipc: host
    shm_size: "1g"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: json-file
      options:
        max-size: "20m"
        max-file: "5"
